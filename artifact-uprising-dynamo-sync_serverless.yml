
plugins:
  - serverless-python-requirements

service: artifactUprisingDynamoSync # NOTE: update this with your service name

# You can pin your service to only deploy with a specific Serverless version
# Check out our docs for more details
# frameworkVersion: "=X.X.X"

provider:
  name: aws
  runtime: python3.6
  stage: dev
  region: us-west-2
  profile: mammothgrowth
  timeout: 300 #Default all functions to max timeout
  environment:
    dynamo_table_projects: ${self:custom.tableNames.projects}
    redshift_url: artifact-2.cf5wz3dozczr.us-west-2.redshift.amazonaws.com
    redshift_port: "5439"
    redshift_user: temp_dynamo_sync
    # redshift_password: 7EHYr1xlzcIF
    redshift_database: artifact_uprising
    redshift_cluster: artifact-2
    redshift_table_projects: artifact_uprising.project_data
    sqs_queue_projects: DynamoRedshiftSyncQueue
    kinesis_queue_projects: ${self:custom.kinesis.redshiftSyncStreamName}
    batch_size: ${self:custom.kinesis.batchSize}
    redshiftSyncDLQName: ${self:custom.kinesis.redshiftSyncDLQName}

# you can add statements to the Lambda function's IAM Role here
  iamRoleStatements:
    - Effect: "Allow"
      Action:
        - "sqs:SendMessage"
        - "sqs:GetQueueUrl"
      Resource: "arn:aws:sqs:us-west-2:240013347679:DynamoRedshiftSyncQueue"
    - Effect: "Allow"
      Action:
        - "sqs:SendMessage"
        - "sqs:GetQueueUrl"
      Resource: "arn:aws:sqs:us-west-2:240013347679:ProjectsRedshiftSyncDeadLetter"
    - Effect: "Allow"
      Action:
        - "sns:Publish"
      Resource: 
        Ref: RedshiftSyncSQSDeadLetterSNS
    - Effect: "Allow"
      Action:
        - "kinesis:PutRecord"
        - "kinesis:PutRecorda"
      Resource: 
        Fn::GetAtt:
          - RedshiftSyncKinesisStream
          - Arn    	
    - Effect: "Allow"
      Action:
        - "redshift:GetClusterCredentials"
        - "redshift:DescribeClusters"
        - "redshift:CreateClusterUser"        
        - "redshift:JoinGroup"
      Resource: "arn:aws:redshift:us-west-2:240013347679:dbuser:*/temp_*"
    - Effect: "Allow"
      Action:
        - "redshift:GetClusterCredentials"
        - "redshift:DescribeClusters"
        - "redshift:CreateClusterUser"        
        - "redshift:JoinGroup"
      Resource: "arn:aws:redshift:us-west-2:240013347679:dbname:*/*"


# you can define service wide environment variables here
#  environment:
#    variable1: value1

# you can add packaging information here
#package:
#  include:
#    - include-me.py
#    - include-me-dir/**
#  exclude:
#    - exclude-me.py
#    - exclude-me-dir/**

functions:
  dynamoProjectsSubscriber:
    handler: lambda_dynamo_subscriber.handle
    events:
      - stream:
          type: dynamodb 
          # arn: ${self:custom.dynamoStreams.projects}
          arn:
            Fn::GetAtt:
              - ProjectsDynamoTable
              - StreamArn

  projectsRedshiftSync:
    handler: lambda_redshift_update.handle
    reservedConcurrency: 1
    events: 
      - stream:
          type: kinesis
          batchSize: ${self:custom.kinesis.batchSize}
          startingPosition: LATEST
          enabled: true
          arn:
            Fn::GetAtt:
              - RedshiftSyncKinesisStream
              - Arn    	
      # - sqs: 
      #     batchSize: 10
      #     arn:
      #       Fn::GetAtt:
      #         - RedshiftSyncSQS
      #         - Arn

    onError: 
      Ref: RedshiftSyncSQSDeadLetterSNS
    vpc:
      securityGroupIds:        
        - sg-055faf05648def1d9
      subnetIds:
        - subnet-0444e9eb1caa17313

        
  projectsRedshiftSyncDLQDrain1:
    handler: lambda_dlq1_drain.handle
    reservedConcurrency: 10
    timeout: 30
    events: 
      - sqs: 
          batchSize: 10
          arn:
            Fn::GetAtt:
              - RedshiftSyncSQSDeadLetter
              - Arn


resources:
 Resources:

  # Mapped update to process in Redshift
    RedshiftSyncKinesisStream:
      Type: "AWS::Kinesis::Stream"
      Properties:
        Name: ${self:custom.kinesis.redshiftSyncStreamName}
        ShardCount: 1 #Shard count controls the concurrency of the Lambda.  1 Shard = 1 Lambda instance
        RetentionPeriodHours: 168  #retain for 1 week
    
  # DLQ for Lambda that processes Redshift Updates.  This goes via SNS
    ProjectsRedshiftSyncDeadLetter:
      Type: "AWS::SQS::Queue"
      Properties:
        QueueName: "ProjectsRedshiftSyncDeadLetter"

  # SNS topic for Lambda to send dead items to
    RedshiftSyncSQSDeadLetterSNS:
      Type: "AWS::SNS::Topic"
      Properties:
        Subscription:
          -
            Endpoint: 
                Fn::GetAtt:
                - ProjectsRedshiftSyncDeadLetter
                - Arn
            Protocol: sqs

    #  Depricated
    RedshiftSyncSQS:
      Type: "AWS::SQS::Queue"
      Properties:
        QueueName: "DynamoRedshiftSyncQueue"
        RedrivePolicy:
          deadLetterTargetArn:
            Fn::GetAtt:
            - RedshiftSyncSQSDeadLetter
            - Arn
          maxReceiveCount: 3

    # Depricated
    RedshiftSyncSQSDeadLetter:
      Type: "AWS::SQS::Queue"
      Properties:
        QueueName: ${self:custom.kinesis.redshiftSyncDLQName}

    ProjectsDynamoTable:
      Type: AWS::DynamoDB::Table
      Properties:
        TableName:  ${self:custom.tableNames.projects}
        AttributeDefinitions:
          - AttributeName: projectId
            AttributeType: S
        KeySchema:
          - AttributeName: projectId
            KeyType: HASH
        ProvisionedThroughput:
          ReadCapacityUnits: 1
          WriteCapacityUnits: 1
        StreamSpecification:
          StreamViewType: NEW_AND_OLD_IMAGES    # RedshiftCluster:
    #   Type: AWS::Redshift::Cluster

custom:
  tableNames:
    projects: artifact-uprising-projects-2-${self:provider.stage}
  pythonRequirements:
    dockerizePip: true
  kinesis:
    redshiftSyncStreamName: ProjectsDynamoDBRedshiftSync
    batchSize: 100
    redshiftSyncDLQName: DynamoRedshiftSyncQueueDeadLetter
