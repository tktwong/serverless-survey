# This file is the main config file for your service.
#
# For full config options, check the docs:
#    docs.serverless.com

service: eminem-fastai-serverless

# You can pin your service to only deploy with a specific Serverless version
frameworkVersion: ">=1.27.1"

provider:
  # you can overwrite defaults here
  name: aws
  runtime: python3.6
  stage: dev
  region: us-west-2
  profile: slsf-superuser
  memorySize: 2048
  timeout: 120
  # you can define API keys to generate here
  apiKeys:
    - ${self:service}_default_${self:provider.stage}


  # you can define service wide environment variables here
  environment:
    BUCKET_NAME: pytorch-serverless-shun
    STATE_DICT_NAME: dogscats_v2_cpu.h5

  # you can define custom configuration variables here
  variables:
    api_version: v2.0.0

  # you can add statements to the Lambda function's IAM Role here
  iamRoleStatements:
    - Effect: Allow
      Action:
        - s3:ListBucket
      Resource: 'arn:aws:s3:::*'
    - Effect: Allow
      Action:
        - s3:GetObject
      Resource: 'arn:aws:s3:::*/**'

# you can add packaging information here
package:
  exclude:
    - package.json
    - package-lock.json
    - README.md
    - node_modules/**
    - tests/**
    - .DS_Store
    - .idea/**

# you can define plugins here
plugins:
  - serverless-python-requirements
custom:
  pythonRequirements:
    dockerizePip: true
    zip: true

#
# Define API endpoints
#
functions:
  predict:
    handler: api/predict.py
    events:
      - schedule: rate(15 minutes) # set CloudWatch function to keep lambda warm
      - http:
          method: GET
          cors: true
          path: ${self:provider.variables.api_version}/predict
          private: true # authorize endpoint with `X-API-KEY` header
          request:
            parameters:
              querystrings:
                predict_text: true