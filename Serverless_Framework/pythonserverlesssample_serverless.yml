service: simple-data-pipline # NOTE: update this with your service name

provider:
  name: aws
  runtime: python3.6
  region: ap-southeast-2
  stage: ${opt:stage, 'dev'}
  timeout: 300

  iamRoleStatements:
    - Effect: "Allow"
      Action:
        - "dynamodb:*"
      Resource:
        - "Fn::GetAtt": [DocumentsTable, Arn]
        - "Fn::Join":
          - "/"
          - - { "Fn::GetAtt": [DocumentsTable, Arn] }
            - "index/*"
    - Effect: "Allow"
      Action:
        - "s3:GetObject"
        - "s3:GetBucketNotification"
        - "s3:PutBucketNotification"
      Resource: arn:aws:s3:::${self:custom.s3bucketName}/*

plugins:
  - serverless-python-requirements
custom:
  tableThroughput: 50
  documentsTableName: DocumentsTable
  s3bucketName: dev.document.files
  pythonRequirements:
    dockerizePip: non-linux
    layer: true

package:
  exclude:
    - bin/**
    - lib/**

functions:
  importCSVToDB:
    handler: handler.importCSVToDB
    layers:
      - {Ref: PythonRequirementsLambdaLayer}
    environment:
      documentsTable: ${self:custom.documentsTableName}
      bucketName: ${self:custom.s3bucketName}
    events:
      - s3:
          bucket: ${self:custom.s3bucketName}
          event: s3:ObjectCreated:Put
          rules:
            - suffix: .csv

resources:
  # DynamoDB
  - ${file(resources/dynamodb-table.yml)}