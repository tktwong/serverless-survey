plugins:
  - serverless-dynamodb-local
  - serverless-offline

service: postcode
# app and org for use with dashboard.serverless.com
app: postcode-app
org: aaluni

provider:
  name: aws
  runtime: nodejs12.x
  # you can overwrite defaults here
  stage: dev
  region: us-east-1
  iamRoleStatements:
    - Effect: Allow
      Action:
        - s3:*
      Resource: "*"
    - Effect: "Allow"
      Action:
        - "s3:GetObject"
      Resource:
        Fn::Join:
          - ""
          - - "arn:aws:s3:::"
            - "Ref": "PostCodeTable"
            - "/*"
    - Effect: "Allow"
      Action:
        - dynamodb:DescribeTable
        - dynamodb:Query
        - dynamodb:Scan
        - dynamodb:GetItem
        - dynamodb:PutItem
        - dynamodb:UpdateItem
        - dynamodb:DeleteItem
        - dynamodb:BatchWriteItem
      Resource: "arn:aws:dynamodb:us-east-1:*:*"
# you can define service wide environment variables here
#  environment:
#    variable1: value1

custom:
  tableName: uk_postcodes
  bucketName: aaluni-csv-upload
  destinationBuckectName: aaluni-csv-processed
  dynamodb:
    # If you only want to use DynamoDB Local in some stages, declare them here
    stages:
      - dev
    start:
      port: 8000
      inMemory: true
      heapInitial: 200m
      heapMax: 1g
      migrate: false
      seed: false
    #  convertEmptyValues: true
    # Uncomment only if you already have a DynamoDB running locally
    # noStart: true

# you can add packaging information here
package:
  #  include:
  #    - include-me.js
  #    - include-me-dir/**
  exclude:
    - .dynamodb/**
    - NSPL*

functions:
  postcodeDataUploader:
    handler: lambdaLoader.handler
    memorySize: 256 # optional, in MB, default is 1024
    timeout: 300 # optional, in seconds, default is 6
    events:
      - s3:
          bucket: ${self:org}-${self:service}-${self:provider.stage}-source
          event: s3:ObjectCreated:*
          rules:
            - suffix: .csv
          existing: true
      # - http:
      #     path: /process
      #     method: post
    environment:
      SOURCE_BUCKET_NAME: ${self:org}-${self:service}-${self:provider.stage}-source
      DESTINATION_BUCKET_NAME: ${self:org}-${self:service}-${self:provider.stage}-processed
      TABLE_NAME: ${self:org}-${self:service}-${self:provider.stage}-${self:custom.tableName}
      BATCH_SIZE: 25

# you can add CloudFormation resource templates here
resources: # CloudFormation template syntax
  Resources: # CloudFormation template syntax
    PostCodeTable:
      Type: AWS::DynamoDB::Table
      Properties:
        TableName: ${self:org}-${self:service}-${self:provider.stage}-${self:custom.tableName}
        AttributeDefinitions:
          - AttributeName: postcode_compact
            AttributeType: S
          - AttributeName: RK
            AttributeType: S
        KeySchema:
          - AttributeName: postcode_compact
            KeyType: HASH
          - AttributeName: RK
            KeyType: RANGE
        ProvisionedThroughput:
          ReadCapacityUnits: 1
          WriteCapacityUnits: 1

    SourceBucket:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:org}-${self:service}-${self:provider.stage}-source

    ProcessedBucket:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:org}-${self:service}-${self:provider.stage}-processed
