# Welcome to Serverless!
#
# This file is the main config file for your service.
# It's very minimal at this point and uses default values.
# You can always add more config options for more control.
# We've included some commented out config examples here.
# Just uncomment any of them to get that config option.
#
# For full config options, check the docs:
#    docs.serverless.com
#
# Happy Coding!

service: s3-to-rds

# You can pin your service to only deploy with a specific Serverless version
# Check out our docs for more details
# frameworkVersion: "=X.X.X"

custom:
  inputbucket: kinetic-kinesis-ingestor
  streambucket: kinetic-kinesis-streams
  stream: kinetic-kinesis-delivery
  role: kinetic-kinesis

provider:
  name: aws
  runtime: nodejs8.10

# you can overwrite defaults here
#  stage: dev
#  region: us-east-1

# you can add statements to the Lambda function's IAM Role here
  iamRoleStatements:
    - Effect: "Allow"
      Action:
        - "firehose:PutRecord"
      Resource:
        Fn::Join:
          - ":"
          - - "arn"
            - "aws"
            - "firehose"
            - "Ref": "AWS::Region"
            - "Ref": "AWS::AccountId"
            - "deliverystream/${self:custom.stream}"
    - Effect: "Allow"
      Action:
        - "ec2:CreateNetworkInterface"
        - "ec2:DescribeNetworkInterfaces"
        - "ec2:DeleteNetworkInterface"
      Resource: "*"

# you can add packaging information here
#package:
#  include:
#    - include-me.js
#    - include-me-dir/**
#  exclude:
#    - exclude-me.js
#    - exclude-me-dir/**

functions:
  s3tokinesis:
    handler: s3_to_kinesis.handler
    events:
      - s3: input

  s3tords:
    handler: s3_to_rds.handler
    events:
      - s3: streams
    environment:
      PGUSER: ${env:PGUSER}
      PGPASSWORD: ${env:PGPASSWORD}
      PGDATABASE: ${env:PGDATABASE}
      PGPORT: 5432
  


#    The following are a few example events you can configure
#    NOTE: Please make sure to change your handler code to work with those events
#    Check the event documentation for details
#    events:
#      - http:
#          path: users/create
#          method: get
#      - s3: ${env:BUCKET}
#      - schedule: rate(10 minutes)
#      - sns: greeter-topic
#      - stream: arn:aws:dynamodb:region:XXXXXX:table/foo/stream/1970-01-01T00:00:00.000
#      - alexaSkill
#      - alexaSmartHome: amzn1.ask.skill.xx-xx-xx-xx
#      - iot:
#          sql: "SELECT * FROM 'some_topic'"
#      - cloudwatchEvent:
#          event:
#            source:
#              - "aws.ec2"
#            detail-type:
#              - "EC2 Instance State-change Notification"
#            detail:
#              state:
#                - pending
#      - cloudwatchLog: '/aws/lambda/hello'
#      - cognitoUserPool:
#          pool: MyUserPool
#          trigger: PreSignUp

#    Define function environment variables here
#   environment:

# you can add CloudFormation resource templates here
resources:
  Resources:
    S3BucketInput:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.inputbucket}
    S3tokinesisLambdaPermissionInputS3:
      Type: "AWS::Lambda::Permission"
      Properties:
        FunctionName:
          "Fn::GetAtt":
            - S3tokinesisLambdaFunction
            - Arn
        Principal: "s3.amazonaws.com"
        Action: "lambda:InvokeFunction"
        SourceAccount:
          Ref: AWS::AccountId
        SourceArn: "arn:aws:s3:::${self:custom.inputbucket}"
    S3BucketStreams:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.streambucket}
    S3tordsLambdaPermissionStreamsS3:
      Type: "AWS::Lambda::Permission"
      Properties:
        FunctionName:
          "Fn::GetAtt":
            - S3tordsLambdaFunction
            - Arn
        Principal: "s3.amazonaws.com"
        Action: "lambda:InvokeFunction"
        SourceAccount:
          Ref: AWS::AccountId
        SourceArn: "arn:aws:s3:::${self:custom.streambucket}"
    KinesisDeliveryStream:
      Type: AWS::KinesisFirehose::DeliveryStream
      Properties:
        DeliveryStreamName: ${self:custom.stream}
        DeliveryStreamType: DirectPut
        S3DestinationConfiguration:
          BucketARN: 
            "Fn::GetAtt":
              - S3BucketStreams
              - Arn
          BufferingHints:
            IntervalInSeconds: 60
            SizeInMBs: 1
          CompressionFormat: "UNCOMPRESSED"
          Prefix: "streams/"
          RoleARN: 
            "Fn::GetAtt":
              - KinesisDeliveryRole
              - Arn
    KinesisDeliveryRole:
      Type: "AWS::IAM::Role"
      Properties:
        AssumeRolePolicyDocument:
          Version: "2012-10-17"
          Statement:
            - Sid: ""
              Effect: Allow
              Principal:
                Service: firehose.amazonaws.com
              Action: "sts:AssumeRole"
              Condition:
                StringEquals:
                  "sts:ExternalId": 
                    "Ref": "AWS::AccountId"
    KinesisDeliveryPolicy:
      Type: "AWS::IAM::Policy"
      Properties:
        PolicyName: firehose_delivery_policy
        PolicyDocument:
          Version: "2012-10-17"
          Statement:
            - Effect: Allow
              Action:
                - "s3:AbortMultipartUpload"
                - "s3:GetBucketLocation"
                - "s3:GetObject"
                - "s3:ListBucket"
                - "s3:ListBucketMultipartUploads"
                - "s3:PutObject"
              Resource:
                - "Fn::Join":
                  - ""
                  - - "arn:aws:s3:::"
                    - "Ref": "S3BucketStreams"
                - "Fn::Join":
                  - ""
                  - - "arn:aws:s3:::"
                    - "Ref": "S3BucketStreams"
                    - "*"
        Roles:
          - "Ref": "KinesisDeliveryRole"

    DatabaseCluster:
      Type: AWS::RDS::DBCluster
      Properties:
        Engine: aurora-postgresql
        DatabaseName: ${env:PGDATABASE}
        MasterUsername: ${env:PGUSER}
        MasterUserPassword: ${env:PGPASSWORD}
        BackupRetentionPeriod: 7
        PreferredBackupWindow: 01:00-02:00
        PreferredMaintenanceWindow: mon:03:00-mon:04:00
        DBSubnetGroupName:
          "Ref": "DatabaseSubnetGroup"
        DBClusterParameterGroupName: default.aurora-postgresql9.6

    DatabaseInstance:
      Type: AWS::RDS::DBInstance
      Properties:
        Engine: aurora-postgresql
        DBInstanceClass: db.r4.large
        DBClusterIdentifier: 
          "Ref": "DatabaseCluster"
          
    DatabaseSubnetGroup:
      Type: AWS::RDS::DBSubnetGroup
      Properties: 
        DBSubnetGroupDescription: Subnet group for database instances
        SubnetIds:
          - "Ref": "DatabaseSubnetAZ1"
          - "Ref": "DatabaseSubnetAZ2"
          
    DatabaseSubnetAZ1:
      Type: AWS::EC2::Subnet
      Properties:
        AvailabilityZone: "us-east-1a"
        CidrBlock: "10.0.0.0/24"
        VpcId:
          "Ref": "DatabaseVPC"
          
    DatabaseSubnetAZ2:
      Type: AWS::EC2::Subnet
      Properties:
        AvailabilityZone: "us-east-1b"
        CidrBlock: "10.0.1.0/24"
        VpcId:
          "Ref": "DatabaseVPC"
          
    DatabaseVPC:
      Type: AWS::EC2::VPC
      Properties:
        CidrBlock: "10.0.0.0/23"
        
    DatabaseSecurityGroup:
      Type: AWS::EC2::SecurityGroup
      Properties:
        GroupName: kinetic-kinesis-db
        GroupDescription: "Connections to the RDS instance"
        SecurityGroupIngress:
          Description: "PostgreSQL Port"
          FromPort: 5432
          ToPort: 5432
          CidrIp:
            "Fn::GetAtt":
              - DatabaseVPC
              - CidrBlock
          IpProtocol: "tcp"
        VpcId:
          "Ref": "DatabaseVPC"

    S3tordsLambdaFunction:
      Type: AWS::Lambda::Function
      DependsOn: DatabaseCluster
      Properties:
        Environment:
          Variables:
            PGHOST:
              "Fn::GetAtt": 
                - DatabaseCluster
                - Endpoint.Address
        VpcConfig:
          SecurityGroupIds:
            - "Fn::GetAtt":
              - DatabaseSecurityGroup
              - GroupId
          SubnetIds:
            - "Ref": "DatabaseSubnetAZ1"
            - "Ref": "DatabaseSubnetAZ2"
      
    S3tokinesisLambdaFunction:
      Type: AWS::Lambda::Function
      DependsOn: KinesisDeliveryStream
      Properties:
        Environment:
          Variables:
            STREAM:
              "Ref": "KinesisDeliveryStream"
  Outputs:
    InputBucketName:
      Description: "S3 Input Bucket"
      Value: 
        "Fn::GetAtt":
          - S3BucketInput
          - DomainName
