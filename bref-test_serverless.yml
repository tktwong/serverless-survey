service: bref

plugins:
  # We need to include the Bref plugin
  - ./vendor/bref/bref
  - serverless-domain-manager

provider:
  name: aws

  # The AWS region in which to deploy (us-east-1 is the default)
  region: ap-southeast-2

  # The stage of the application, e.g. dev, production, stagingâ€¦ ('dev' is the default)
  stage: dev
  runtime: provided.al2
  environment:
    APP_NAME: 'Bref Demo'
    APP_ENV: production
    APP_KEY: ${ssm:/bref-dev/APP_KEY}
    APP_DEBUG: false
    APP_URL: ${ssm:/bref-dev/APP_URL}
    LOG_CHANNEL: stderr
    FILESYSTEM_DRIVER: s3
    AWS_PUBLIC_BUCKET: ${ssm:/bref-dev/AWS_PUBLIC_BUCKET}
    SQS_QUEUE: !Ref AlertQueue
    QUEUE_CONNECTION: sqs
    DB_CONNECTION: ${ssm:/bref-dev/DB_CONNECTION}
    DB_HOST: ${ssm:/bref-dev/DB_HOST}
    DB_PORT: ${ssm:/bref-dev/DB_PORT}
    DB_DATABASE: ${ssm:/bref-dev/DB_DATABASE}
    DB_USERNAME: ${ssm:/bref-dev/DB_USERNAME}
    DB_PASSWORD: ${ssm:/bref-dev/DB_PASSWORD}
    CACHE_DRIVER: dynamodb
    DYNAMODB_CACHE_TABLE: bref-dev
    DYNAMODB_ENDPOINT: https://dynamodb.${self:provider.region}.amazonaws.com
    SENTRY_LARAVEL_DSN: ${ssm:/bref-dev/SENTRY_LARAVEL_DSN}
    MAIL_MAILER: ${ssm:/bref-dev/MAIL_MAILER}
    MAILGUN_DOMAIN: ${ssm:/bref-dev/MAILGUN_DOMAIN}
    MAILGUN_SECRET: ${ssm:/bref-dev/MAILGUN_SECRET}
    MAIL_FROM_ADDRESS: ${ssm:/bref-dev/MAIL_FROM_ADDRESS}
    MAIL_FROM_NAME: ${ssm:/bref-dev/MAIL_FROM_NAME}
    MAIL_TO_ADDRESS: ${ssm:/bref-dev/MAIL_TO_ADDRESS}
    MIX_ASSET_URL: ${ssm:/bref-dev/MIX_ASSET_URL}

    AWS_BUCKET: # environment variable for Laravel
      Ref: Storage

  iamRoleStatements:
    # Allow Lambda to read and write files in the S3 buckets
    - Effect: Allow
      Action:
        - 's3:*'
      Resource:
        - Fn::GetAtt: [ Storage, Arn ]  # the storage bucket
        - Fn::Join: [ '', [ Fn::GetAtt: [ Storage, Arn ], '/*' ] ]

    # Allow Lambda to read and write to the DynamoDB
    - Effect: Allow
      Action:
        - 'dynamodb:*'
      Resource:
        - Fn::GetAtt: [ Cache, Arn ]  # the dynamo db
        - Fn::Join: [ '', [ Fn::GetAtt: [ Cache, Arn ], '/*' ] ]

    # Allows our code to interact with SQS
    - Effect: Allow
      Action: [ sqs:SendMessage, sqs:DeleteMessage ]
      Resource: !GetAtt AlertQueue.Arn

package:
  # Directories to exclude from deployment
  exclude:
    - node_modules/**
    - public/storage
    - resources/assets/**
    - storage/**
    - tests/**

functions:
  # This function runs the Laravel website/API
  web:
    handler: public/index.php
    timeout: 28 # in seconds (API Gateway has a timeout of 29 seconds)
    layers:
      - ${bref:layer.php-74-fpm}
    events:
      - httpApi: '*'

  # This function lets us run artisan commands in Lambda
  artisan:
    handler: artisan
    timeout: 120 # in seconds
    layers:
      - ${bref:layer.php-74} # PHP
      - ${bref:layer.console} # The "console" layer

  # This function lets us run the SQS Queue
  worker:
    handler: worker.php
    layers:
      - ${bref:layer.php-74}
    events:
      # Declares that our worker is triggered by jobs in SQS
      - sqs:
          arn: !GetAtt AlertQueue.Arn
          # If you create the queue manually, the line above could be:
          # arn: 'arn:aws:sqs:us-east-1:1234567890:my_sqs_queue'
          # Only 1 item at a time to simplify error handling
          batchSize: 1

  # This is the function that lets us the the Schedule
  schedule:
    handler: artisan
    layers:
      - ${bref:layer.php-74} # PHP runtime
      - ${bref:layer.console} # Console layer
    events:
      - schedule:
          rate: rate(1 minute)
          input: '"schedule:run"'

resources:
  Resources:
    # Public S3 Bucket for Resources
    Storage:
      Type: AWS::S3::Bucket

    StorageBucketPolicy:
      Type: AWS::S3::BucketPolicy
      Properties:
        Bucket: !Ref Storage # References the bucket we defined above
        PolicyDocument:
          Statement:
            - Effect: Allow
              Principal: '*' # everyone
              Action: 's3:GetObject' # to read
              Resource: !Join [ '/', [ !GetAtt Storage.Arn, '*' ] ] # things in the bucket

    Cache:
      Type: AWS::DynamoDB::Table
      Properties:
        TableName: ${self:provider.environment.DYNAMODB_CACHE_TABLE}
        AttributeDefinitions:
          - AttributeName: key
            AttributeType: S
        KeySchema:
          - AttributeName: key
            KeyType: HASH
        ProvisionedThroughput:
          ReadCapacityUnits: 1
          WriteCapacityUnits: 1

    # The SQS queue
    AlertQueue:
      Type: AWS::SQS::Queue
      Properties:
        RedrivePolicy:
          maxReceiveCount: 3 # jobs will be retried up to 3 times
          # Failed jobs (after the retries) will be moved to the other queue for storage
          deadLetterTargetArn: !GetAtt DeadLetterQueue.Arn

    # Failed jobs will go into that SQS queue to be stored, until a developer looks at these errors
    DeadLetterQueue:
      Type: AWS::SQS::Queue
      Properties:
        MessageRetentionPeriod: 1209600 # maximum retention: 14 days

custom:
  customDomain:
    domainName: bref-test.robmellett.dev
    basePath: ''
    stage: ${self:provider.stage}
    createRoute53Record: false
    endpointType: 'regional'
    securityPolicy: tls_1_2
    apiType: http
    region: ${self:provider.region}
