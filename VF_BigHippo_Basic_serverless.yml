# Welcome to Serverless!
#
# This file is the main config file for your service.
# It's very minimal at this point and uses default values.
# You can always add more config options for more control.
# We've included some commented out config examples here.
# Just uncomment any of them to get that config option.
#
# For full config options, check the docs:
#    docs.serverless.com
#
# Happy Coding!

# Service Name
service: vf-bighippo-basic-final

# Provider Details
provider:
  name: aws
  runtime: nodejs12.x
  # Environment Variables for Lambda Function
  environment:
    DYNAMODB_HIPPO_TABLE: ${self:custom.DYNAMODB_HIPPO_TABLE}
    SOURCE_BUCKET_NAME: ${self:custom.SOURCE_BUCKET_NAME}
  stage: dev
  region: us-east-1
  # IAM Role for the Lambda function
  iamRoleStatements:
    - Effect: "Allow"
      Action:
        - "s3:*"
      Resource: "*"
    - Effect: "Allow"
      Action: 
        - dynamodb:PutItem
      Resource: arn:aws:dynamodb:#{AWS::Region}:#{AWS::AccountId}:table/${self:custom.DYNAMODB_HIPPO_TABLE}

custom:
  SOURCE_BUCKET_NAME: ${self:service}-vf-mloller-s3-to-dynamo
  DYNAMODB_HIPPO_TABLE: ${self:service}-hippos-${self:provider.stage}
  DYNAMODB_ARN: arn:aws:dynamodb:#{AWS::Region}:#{AWS::AccountId}:table/${self:custom.DYNAMODB_HIPPO_TABLE}
  READANDCOPY_FUNCTION_NAME: ${self:service}-vf-read-copy-to-dynamo-${self:provider.stage}
  READANDCOPY_ARN: arn:aws:lambda:#{AWS::Region}:#{AWS::AccountId}:function:${self:custom.READANDCOPY_FUNCTION_NAME}
  READANDCOPYROLE_ARN: arn:aws:iam::#{AWS::AccountId}:role/${self:service}-${self:provider.stage}-#{AWS::Region}-lambdaRole
  FILENAME: Fiona.json
  INVOKER_FUNCTION_NAME: ${self:service}-Invoker

plugins:
  - plugin
  - serverless-pseudo-parameters

functions:
  copyToDynamoOnInit:    
    handler: handler.readAndCopy
    name: ${self:custom.READANDCOPY_FUNCTION_NAME}
    description: Reads objects in s3, attempts to convert to JSON, populates data in Dynamo table

# you can add CloudFormation resource templates here
resources:
  Resources:
    #DynamoDB Table for Hippo data to eventually be stored
    HippoTable:
      Type: 'AWS::DynamoDB::Table'
      Properties:
        TableName: ${self:custom.DYNAMODB_HIPPO_TABLE}
        AttributeDefinitions:
          - AttributeName: id
            AttributeType: S
        KeySchema:
          - AttributeName: id
            KeyType: HASH
        BillingMode: PAY_PER_REQUEST

    S3Bucket:
      Type: "AWS::S3::Bucket"
      DeletionPolicy: Retain
      Properties:
        BucketName: ${self:custom.SOURCE_BUCKET_NAME}
    
    S3BucketPolicy:
      Type: "AWS::S3::BucketPolicy"
      Properties:
        Bucket: !Ref S3Bucket
        PolicyDocument:
          Statement:
            - Sid: "AllowLambdaRead"
              Effect: "Allow"
              Action: "s3:*"
              Principal:
                AWS:
                  Fn::Join:
                    - " "
                    -
                      - ${self:custom.READANDCOPYROLE_ARN}
              Resource:
                Fn::Join:
                  - ""
                  -
                    - "arn:aws:s3:::"
                    - ${self:custom.SOURCE_BUCKET_NAME}
                    - "/*"

    LambdaIAMRole:
      Type: 'AWS::IAM::Role'
      Properties:
        AssumeRolePolicyDocument:
          Version: '2012-10-17'
          Statement:
            - Effect: Allow
              Principal:
                Service:
                  - lambda.amazonaws.com
              Action:
                - 'sts:AssumeRole'
        Path: /
        Policies:
          - PolicyName: root
            PolicyDocument:
              Version: '2012-10-17'
              Statement:
                - Effect: "Allow"
                  Action:
                    - "s3:*"
                  Resource: "*"
                - Effect: Allow
                  Action:
                    - 'logs:CreateLogGroup'
                    - 'logs:CreateLogStream'
                    - 'logs:PutLogEvents'
                  Resource: 'arn:aws:logs:*:*:*'

    CustomPutObject:
      Type: AWS::Lambda::Function
      Properties:
        FunctionName: ${self:custom.INVOKER_FUNCTION_NAME}
        Description: puts object into s3
        Handler: index.handler
        Runtime: python3.6
        Role: !GetAtt 'LambdaIAMRole.Arn'
        Timeout: 240
        Environment:
          Variables:
            bucketName: ${self:custom.SOURCE_BUCKET_NAME}
        Code:
          ZipFile: |
              import json
              import boto3
              import time
              import os
              import uuid
              import cfnresponse
              from io import BytesIO

              def handler(event, context):

                  responseData = {}
                  physicalResourceId = {}
                  
                  bucket = os.environ["bucketName"]

                  id = uuid.uuid4()

                  jsonDict = {
                      "id": str(id),
                      "name": "George",
                      "species": "Common",
                      "location": "Sacramento Zoo",
                      "food": "Corndogs"
                  }
                  
                  s3 = boto3.client('s3')
                  
                  json_encode_data = json.dumps(jsonDict).encode('utf-8')
                  fileobj = BytesIO(json_encode_data)
                  s3.upload_fileobj(fileobj, bucket, 'George.json')
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData, physicalResourceId )
    
    Primerinvoke:
      Type: AWS::CloudFormation::CustomResource
      DependsOn: CustomPutObject
      Version: "1.0"
      Properties:
        ServiceToken: !GetAtt CustomPutObject.Arn

